{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e591631",
   "metadata": {},
   "source": [
    "# ç»éªŒ\n",
    "\n",
    "1. å¯¹äºä¸åŒçš„æ•°é‡çš„åˆ†ç±»ç‰¹å¾çš„å¤„ç†æ–¹å¼é€‰æ‹©ï¼š\n",
    "   1. è¿ç»­å€¼ä½¿ç”¨å½’ä¸€åŒ–ã€‚\n",
    "   2. low-cardinality ç‰¹å¾é‡‡ç”¨label encodingçš„æ–¹å¼è¿›è¡Œç¼–ç ã€‚\n",
    "      1. åˆ†ç•Œçº¿åœ¨äºç±»åˆ«æ•°é‡ä¸º10ã€‚\n",
    "   3.  high-cardinality ç‰¹å¾é‡‡ç”¨ Target Encoding çš„æ–¹å¼è¿›è¡Œç¼–ç ã€‚\n",
    "2. kmeansä¸å»ºè®®ä½¿ç”¨ç½‘æ ¼æœç´¢æ¥è·å–æœ€ä¼˜å€¼ï¼Œå®¹æ˜“å‡ºç°æŠ¥é”™ã€‚ç›´æ¥æ‰‹åŠ¨æœç´¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743835d",
   "metadata": {},
   "source": [
    "# é¢˜ç›®\n",
    "\n",
    "## æ•°æ®è¯´æ˜\n",
    "\n",
    "Bob çš„åˆåˆ›æ‰‹æœºå…¬å¸éœ€è¦ç§‘å­¦å®šä»·ç­–ç•¥ä»¥å¯¹æŠ—è‹¹æœã€ä¸‰æ˜Ÿç­‰å·¨å¤´ã€‚ä»–æ”¶é›†äº† 2000+ æ¬¾æ‰‹æœºçš„ç¡¬ä»¶è§„æ ¼æ•°æ®ï¼Œè¦æ±‚ä½ æ„å»ºä»·æ ¼åˆ†æ¡£é¢„æµ‹æ¨¡å‹ã€‚æ ¹æ®è¡Œä¸šæƒ¯ä¾‹ï¼Œä»·æ ¼åˆ†ä¸º4æ¡£ï¼š\n",
    "0=ä½ç«¯(ï¼œ$200) | 1=ä¸­ç«¯($200-$400) | 2=é«˜ç«¯($400-$600) | 3=æ——èˆ°(ï¼$600)\n",
    "\n",
    "å­—æ®µè¯´æ˜ï¼ˆ21ä¸ªå­—æ®µï¼‰\n",
    "|å­—æ®µå\t|ç±»å‹\t|è¯´æ˜\t|ç¤ºä¾‹å€¼|\n",
    "|---|---|---|---|\n",
    "|id\t|æ•°å€¼\t|æ‰‹æœºå”¯ä¸€IDï¼ˆå»ºæ¨¡æ—¶å¿½ç•¥ï¼‰\t|3|\n",
    "|battery_power\t|æ•°å€¼\t|ç”µæ± å®¹é‡(mAh)\t|1024|\n",
    "|blue\t|åˆ†ç±»\t|è“ç‰™æ”¯æŒï¼š0=æ— ,1=æœ‰\t|1|\n",
    "|clock_speed\t|æ•°å€¼\t|å¤„ç†å™¨ä¸»é¢‘(GHz)\t|2.5|\n",
    "|dual_sim\t|åˆ†ç±»\t|åŒå¡æ”¯æŒï¼š0=æ— ,1=æœ‰\t|0|\n",
    "|fc\t|æ•°å€¼\t|å‰ç½®æ‘„åƒå¤´åƒç´ (MP)\t|8|\n",
    "|four_g\t|åˆ†ç±»\t|4Gæ”¯æŒï¼š0=æ— ,1=æœ‰\t|1|\n",
    "|int_memory\t|æ•°å€¼\t|å†…éƒ¨å­˜å‚¨(GB)|\t64|\n",
    "|m_dep\t|æ•°å€¼\t|æ‰‹æœºåšåº¦(cm)\t|0.8|\n",
    "|mobile_wt\t|æ•°å€¼\t|æ‰‹æœºé‡é‡(g)\t|188|\n",
    "|n_cores|\tæ•°å€¼\t|å¤„ç†å™¨æ ¸å¿ƒæ•°\t|8|\n",
    "|pc\t|æ•°å€¼\t|ä¸»æ‘„åƒå¤´åƒç´ (MP)\t|13|\n",
    "|px_height\t|æ•°å€¼\t|å±å¹•å‚ç›´åˆ†è¾¨ç‡(åƒç´ )\t|905|\n",
    "|px_width|\tæ•°å€¼\t|å±å¹•æ°´å¹³åˆ†è¾¨ç‡(åƒç´ )\t|1988|\n",
    "|ram\t|æ•°å€¼\t|è¿è¡Œå†…å­˜(MB)\t|2632|\n",
    "|sc_h\t|æ•°å€¼\t|å±å¹•é«˜åº¦(cm)\t|15|\n",
    "|sc_w\t|æ•°å€¼\t|å±å¹•å®½åº¦(cm)\t|7|\n",
    "|talk_time\t|æ•°å€¼\t|é€šè¯æ—¶é•¿(å°æ—¶)\t|12|\n",
    "|three_g\t|åˆ†ç±»\t|3Gæ”¯æŒï¼š0=æ— ,1=æœ‰\t|1|\n",
    "|touch_screen\t|åˆ†ç±»\t|è§¦æ‘¸å±ï¼š0=æ— ,1=æœ‰\t|1|\n",
    "|wifi\t|åˆ†ç±»\t|WiFiæ”¯æŒï¼š0=æ— ,1=æœ‰\t|1|\n",
    "|price_range\t|åˆ†ç±»\t|ç›®æ ‡å˜é‡ï¼šä»·æ ¼åˆ†æ¡£\t|2|\n",
    "\n",
    "æ³¨æ„ï¼šæµ‹è¯•é›†ä¸å« price_range å­—æ®µ\n",
    "\n",
    "## ä»»åŠ¡è¯´æ˜\n",
    "å®Œæˆä»¥ä¸‹æµç¨‹ï¼š\n",
    "\n",
    "1. æ•°æ®å¤„ç†\n",
    "   - å¤„ç†ç¼ºå¤±å€¼ï¼špx_height å’Œ px_width æœ‰å°‘é‡ç¼ºå¤±ï¼Œç”¨å‡å€¼å¡«å……ã€‚\n",
    "   - å¤„ç†å¼‚å¸¸å€¼ï¼špx_height å’Œ px_width ä¸º0çš„è®°å½•è§†ä¸ºå¼‚å¸¸å€¼ï¼Œç›´æ¥åˆ é™¤ã€‚\n",
    "   - æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾ï¼šæ ‡å‡†åŒ–æ‰€æœ‰æ•°å€¼ç‰¹å¾ï¼ˆä½¿ç”¨StandardScalerï¼‰ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºbattery_power, ram, px_height, px_widthç­‰ã€‚\n",
    "   - æ‰€æœ‰é¢„å¤„ç†æ“ä½œï¼ˆç¼ºå¤±å€¼å¡«å……ã€å¼‚å¸¸å€¼å¤„ç†ã€æ ‡å‡†åŒ–ï¼‰\n",
    "   - å¿…é¡»åŒæ—¶åº”ç”¨äºè®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "2. æ¨¡å‹æ„å»º\n",
    "   - é€‰æ‹©åˆé€‚çš„åˆ†ç±»æ¨¡å‹\n",
    "   - åœ¨è®­ç»ƒé›†ä¸Šä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯è®¡ç®—F1-scoreï¼ˆå®å¹³å‡ï¼‰ä½œä¸ºè‡ªè¯„ä¼°æŒ‡æ ‡\n",
    "3. é¢„æµ‹ä¸ä¿å­˜\n",
    "   - é¢„æµ‹æµ‹è¯•é›† test.csv çš„ä»·æ ¼åˆ†æ¡£\n",
    "   - ç”Ÿæˆæäº¤æ–‡ä»¶ predictions.csv æ ¼å¼ï¼š\n",
    "        ```csv\n",
    "        id,price_range\n",
    "        1000,1\n",
    "        1001,3\n",
    "        ...\n",
    "        ```\n",
    "   \n",
    "## æäº¤ç‰©\n",
    "\n",
    "1. æ¨¡å‹æ–‡ä»¶\n",
    "   - model.pkl\n",
    "   - ä½¿ç”¨joblibä¿å­˜ï¼š\n",
    "   - joblib.dump(model, 'model.pkl')\n",
    "2. é¢„æµ‹ç»“æœæ–‡ä»¶\n",
    "   - predictions.csvï¼ˆå«ä¸¤åˆ—ï¼šid å’Œé¢„æµ‹çš„ price_rangeï¼‰\n",
    "   - ä»¥ä¸Šä¸¤ä¸ªæ–‡ä»¶ä¸€åŒæ‰“åŒ…ä¸ºä¸€ä¸ªå‹ç¼©åŒ…æ–‡ä»¶åæäº¤ï¼Œå‘½åä¸ºï¼šsubmit.zip\n",
    "3. åœ¨ç­”é¢˜åŒºé¢˜å†™è‡ªè¯„ä¼°F1-scoreï¼ˆå®å¹³å‡ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa3cd8",
   "metadata": {},
   "source": [
    "# å¯¼å…¥åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0ebfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, roc_curve, make_scorer, confusion_matrix, classification_report, RocCurveDisplay, auc\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# from ModelInformation import KFoldTargetEncoder, numeric_features, low_card_features, categorical_features\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067e8f4",
   "metadata": {},
   "source": [
    "# ç¡®å®šæ¨¡å‹ç±»åˆ«\n",
    "\n",
    "1. æ˜¯åˆ†ç±»æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff81e5c",
   "metadata": {},
   "source": [
    "# è¯»å–æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca8c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/2/train.csv')\n",
    "test = pd.read_csv('./Data/2/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca26d71",
   "metadata": {},
   "source": [
    "# æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827bd56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
       "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
       "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
       "       'touch_screen', 'wifi', 'price_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f036f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of blue sort 2\n",
      "number of dual_sim sort 2\n",
      "number of four_g sort 2\n",
      "number of three_g sort 2\n",
      "number of touch_screen sort 2\n",
      "number of wifi sort 2\n"
     ]
    }
   ],
   "source": [
    "def StatisticFeature(df):\n",
    "    # print(PeopleInfo_selected['Sex'].value_counts()) è¿™æ˜¯ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ•°é‡ã€‚\n",
    "    print('number of blue sort {}'.format(df['blue'].nunique()))\n",
    "    print('number of dual_sim sort {}'.format(df['dual_sim'].nunique()))\n",
    "    print('number of four_g sort {}'.format(df['four_g'].nunique()))\n",
    "    print('number of three_g sort {}'.format(df['three_g'].nunique()))\n",
    "    print('number of touch_screen sort {}'.format(df['touch_screen'].nunique()))\n",
    "    print('number of wifi sort {}'.format(df['wifi'].nunique()))\n",
    "StatisticFeature(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee12b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']\n",
    "low_cardinality_features = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']\n",
    "\n",
    "# print(len(numeric_features))\n",
    "# print(len(numeric_features)+ len(low_cardinality_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87df9d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 21) (1000, 21)\n",
      "{'price_range', 'id'}\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®å½¢çŠ¶ã€‚\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "trainset = set(train.columns)\n",
    "testset = set(test.columns)\n",
    "# æ•°æ®åˆ—çš„ä¸åŒã€‚\n",
    "print(testset.symmetric_difference(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc4ee27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
       "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
       "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
       "       'touch_screen', 'wifi', 'price_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54287cba",
   "metadata": {},
   "source": [
    "# æ•°æ®é¢„å¤„ç†\n",
    "\n",
    "## æ•°æ®åˆçº§å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b105ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9976\\4219749616.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna(train[col].mean(), inplace=True)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9976\\4219749616.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[col].fillna(test[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for col in ['px_height', 'px_width']:\n",
    "    train[col] = train[col].replace(0, np.nan)  # å°†0è§†ä¸ºç¼ºå¤±\n",
    "    train[col].fillna(train[col].mean(), inplace=True)\n",
    "\n",
    "    test[col] = test[col].replace(0, np.nan)  # å°†0è§†ä¸ºç¼ºå¤±\n",
    "    test[col].fillna(test[col].mean(), inplace=True)\n",
    "\n",
    "# åˆ é™¤æ— æ„ä¹‰çš„åˆ—ã€‚\n",
    "test.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# è·å–æ ‡ç­¾åˆ—å’Œç‰¹å¾åˆ—ã€‚\n",
    "labels = train['price_range'].astype(int)\n",
    "samples = train.drop(columns=['price_range'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0bbd6",
   "metadata": {},
   "source": [
    "## æ•°æ®é«˜çº§å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "815d0910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1213: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬ä¸€é˜¶æ®µæœ€ä¼˜å‚æ•°ï¼š {'classifier__penalty': 'l1', 'classifier__l1_ratio': np.float64(0.3333333333333333), 'classifier__C': np.float64(11.288378916846883)}\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬äºŒé˜¶æ®µæœ€ä¼˜å‚æ•°ï¼š {'classifier__C': np.float64(5.644189458423441), 'classifier__penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), low_cardinality_features),\n",
    "#     # ('target_encoder', ce.TargetEncoder(cols=categorical_features), categorical_features),\n",
    "    # ('target_encoder', KFoldTargetEncoder(cols=categorical_features), categorical_features),\n",
    "    # ('passthrough', '')\n",
    "])\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='saga'))\n",
    "               ])\n",
    "\n",
    "X_train, X_Validation, y_train, y_Validation = train_test_split(samples, labels, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# æ³¨æ„æœ¬é¢˜æ˜¯ä»¥f1ä¸ºç›®æ ‡ã€‚\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'f1': make_scorer(f1_score),\n",
    "           'roc_auc': make_scorer(roc_auc_score)}\n",
    "# scoring = {'f1': make_scorer(f1_score)}\n",
    "\n",
    "\n",
    "# ç¬¬ä¸€é˜¶æ®µçš„ç²—æœç´¢ã€‚\n",
    "parameters_dist = {\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'classifier__C': np.logspace(-4, 4, 20),\n",
    "    'classifier__l1_ratio': np.linspace(0, 1, 10), \n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pl,\n",
    "    param_distributions=parameters_dist,\n",
    "    n_iter=20,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',  # ä½¿ç”¨f1ä½œä¸ºæœ€ç»ˆæ¨¡å‹çš„è¯„ä¼°æ ‡å‡†\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"ç¬¬ä¸€é˜¶æ®µæœ€ä¼˜å‚æ•°ï¼š\", random_search.best_params_)\n",
    "\n",
    "# ç¬¬äºŒé˜¶æ®µï¼šç½‘æ ¼æœç´¢ï¼ˆç²¾è°ƒï¼‰\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "penalty = best_params['classifier__penalty']\n",
    "C = best_params['classifier__C']\n",
    "\n",
    "# æ„é€ ç²¾è°ƒç½‘æ ¼\n",
    "if penalty == 'elasticnet':\n",
    "    param_grid = {\n",
    "        'classifier__penalty': [penalty],\n",
    "        'classifier__C': [C * 0.5, C, C * 2],\n",
    "        'classifier__l1_ratio': np.linspace(0.2, 0.8, 5),\n",
    "    }\n",
    "else:\n",
    "    param_grid = {\n",
    "        'classifier__penalty': [penalty],\n",
    "        'classifier__C': [C * 0.5, C, C * 2],\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pl,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"ç¬¬äºŒé˜¶æ®µæœ€ä¼˜å‚æ•°ï¼š\", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff016dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV Macro F1-score: 0.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scores = cross_val_score(best_model, train, labels, cv=cv, scoring='f1_macro')\n",
    "\n",
    "print(f\"5-fold CV Macro F1-score: {f1_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "831c6586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æµ‹è¯•é›†è¯„ä¼°:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75       500\n",
      "           1       0.53      0.36      0.43       500\n",
      "           2       0.00      0.00      0.00       500\n",
      "           3       0.59      0.99      0.74       500\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.43      0.58      0.48      2000\n",
      "weighted avg       0.43      0.58      0.48      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# 5. æµ‹è¯•é›†è¯„ä¼°\n",
    "y_pred = best_model.predict(train)\n",
    "# y_pred\n",
    "print(\"\\næµ‹è¯•é›†è¯„ä¼°:\")\n",
    "print(classification_report(y_true=labels, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f082056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5845\n",
      "mean accuracy :0.531\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = best_model.predict(train)\n",
    "y_proba = best_model.predict_proba(train)[:, 1]\n",
    "print('accuracy: {}'.format(accuracy_score(labels, y_pred)))\n",
    "\n",
    "scores = cross_val_score(best_model, samples, labels, cv=5)\n",
    "print('mean accuracy :{}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d58cd7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data/model.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, './Data/model.pkl')\n",
    "# joblib.dump(best_model.named_steps['preprocessor'].get_feature_names_out(), './Data/feature_names.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2525955",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(best_model.predict(test))\n",
    "y_pred.to_csv('./Data/predictions.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499f203",
   "metadata": {},
   "source": [
    "# å¤šä¸ªæ¨¡å‹çš„æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 1. åŠ è½½ç¤ºä¾‹æ•°æ®\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)\n",
    "\n",
    "# 2. å®šä¹‰æ¨¡å‹å­—å…¸\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(solver='saga', max_iter=10000),\n",
    "    \"SVC\": SVC(probability=True),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# 3. å®šä¹‰æ¯ä¸ªæ¨¡å‹çš„æœç´¢ç©ºé—´\n",
    "param_distributions = {\n",
    "    \"LogisticRegression\": {\n",
    "        'clf__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'clf__C': np.logspace(-4, 4, 10),\n",
    "        'clf__l1_ratio': np.linspace(0, 1, 5)  # ä»…åœ¨ elasticnet ä¸­æœ‰æ•ˆ\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'clf__C': np.logspace(-3, 2, 6),\n",
    "        'clf__gamma': ['scale', 'auto'],\n",
    "        'clf__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [None, 5, 10, 20],\n",
    "        'clf__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        'clf__max_depth': [None, 5, 10, 20],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. è‡ªåŠ¨åŒ–è°ƒå‚å’Œè¯„ä¼°\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” æ­£åœ¨æœç´¢æ¨¡å‹: {name}\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_distributions[name],\n",
    "        n_iter=20,\n",
    "        scoring='accuracy',\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        verbose=0,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    best_models[name] = search.best_estimator_\n",
    "    \n",
    "    print(f\"âœ… æœ€ä½³å‚æ•°: {search.best_params_}\")\n",
    "    print(f\"ğŸ“Š äº¤å‰éªŒè¯å‡†ç¡®ç‡: {search.best_score_:.4f}\")\n",
    "\n",
    "    # è¯„ä¼°æµ‹è¯•é›†\n",
    "    y_pred = search.predict(X_test)\n",
    "    print(\"ğŸ“‹ æµ‹è¯•é›†ç»“æœ:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# å¯é€‰ï¼šæ¯”è¾ƒä¸åŒæ¨¡å‹æœ€ç»ˆåœ¨æµ‹è¯•é›†çš„å‡†ç¡®ç‡ç­‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811683cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ­£åœ¨æœç´¢æ¨¡å‹: LogisticRegression\n",
      "âœ… æ¨¡å‹ LogisticRegression çš„æµ‹è¯•å‡†ç¡®ç‡: 0.9649\n",
      "ğŸ” æ­£åœ¨æœç´¢æ¨¡å‹: RandomForest\n",
      "âœ… æ¨¡å‹ RandomForest çš„æµ‹è¯•å‡†ç¡®ç‡: 0.9561\n",
      "ğŸ” æ­£åœ¨æœç´¢æ¨¡å‹: SVC\n",
      "âœ… æ¨¡å‹ SVC çš„æµ‹è¯•å‡†ç¡®ç‡: 0.9825\n",
      "\n",
      "ğŸ† æœ€ä¼˜æ¨¡å‹ä¸º: SVCï¼Œå‡†ç¡®ç‡: 0.9825\n",
      "ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º: SVC_best_model.pkl\n",
      "\n",
      "ğŸ“Š ç‰¹å¾é‡è¦æ€§ï¼š\n",
      "âŒ è¯¥æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§è¾“å‡ºã€‚\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. åŠ è½½æ•°æ®\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. å®šä¹‰æ¨¡å‹åŠè°ƒå‚ç©ºé—´\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(solver='saga', max_iter=10000),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"SVC\": SVC(probability=True)\n",
    "}\n",
    "\n",
    "param_distributions = {\n",
    "    \"LogisticRegression\": {\n",
    "        'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'clf__C': np.logspace(-4, 4, 10),\n",
    "        'clf__l1_ratio': np.linspace(0, 1, 5)\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [3, 5, 10, None],\n",
    "        'clf__max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'clf__C': np.logspace(-2, 2, 5),\n",
    "        'clf__gamma': ['scale', 'auto'],\n",
    "        'clf__kernel': ['linear', 'rbf']\n",
    "    }\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"LogisticRegression\": {\n",
    "        'clf__penalty': ['l1', 'elasticnet'],\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__l1_ratio': [0.5, 0.7]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__max_depth': [5, 10],\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'clf__C': [1, 10],\n",
    "        'clf__kernel': ['rbf'],\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. æœç´¢å¹¶ä¿å­˜æœ€ä¼˜æ¨¡å‹\n",
    "best_score = 0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "best_pipeline = None\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"ğŸ” æ­£åœ¨æœç´¢æ¨¡å‹: {name}\")\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    # 1. éšæœºæœç´¢\n",
    "    rand_search = RandomizedSearchCV(pipe, param_distributions[name], n_iter=10,\n",
    "                                     scoring='accuracy', cv=cv, random_state=42, n_jobs=-1)\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. ç½‘æ ¼æœç´¢ï¼ˆä»¥éšæœºæœç´¢ç»“æœä¸ºåŸºç¡€ï¼‰\n",
    "    best_params = rand_search.best_params_\n",
    "    grid_params = param_grids.get(name, {})\n",
    "    grid_search = GridSearchCV(pipe, grid_params, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    acc = accuracy_score(y_test, grid_search.predict(X_test))\n",
    "    print(f\"âœ… æ¨¡å‹ {name} çš„æµ‹è¯•å‡†ç¡®ç‡: {acc:.4f}\")\n",
    "    \n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model_name = name\n",
    "        best_pipeline = grid_search\n",
    "\n",
    "# 4. ä¿å­˜æœ€ä¼˜æ¨¡å‹\n",
    "print(f\"\\nğŸ† æœ€ä¼˜æ¨¡å‹ä¸º: {best_model_name}ï¼Œå‡†ç¡®ç‡: {best_score:.4f}\")\n",
    "joblib.dump(best_model, f\"{best_model_name}_best_model.pkl\")\n",
    "print(f\"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º: {best_model_name}_best_model.pkl\")\n",
    "\n",
    "# 5. æ‰“å°ç‰¹å¾é‡è¦æ€§\n",
    "print(\"\\nğŸ“Š ç‰¹å¾é‡è¦æ€§ï¼š\")\n",
    "feature_names = X.columns\n",
    "try:\n",
    "    if hasattr(best_model.named_steps['clf'], 'coef_'):\n",
    "        coefs = best_model.named_steps['clf'].coef_\n",
    "        if coefs.ndim == 2:\n",
    "            coefs = coefs[0]\n",
    "        for name, coef in sorted(zip(feature_names, coefs), key=lambda x: abs(x[1]), reverse=True):\n",
    "            print(f\"{name}: {coef:.4f}\")\n",
    "    elif hasattr(best_model.named_steps['clf'], 'feature_importances_'):\n",
    "        importances = best_model.named_steps['clf'].feature_importances_\n",
    "        for name, importance in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"{name}: {importance:.4f}\")\n",
    "    else:\n",
    "        print(\"âŒ è¯¥æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§è¾“å‡ºã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç‰¹å¾é‡è¦æ€§æå–å¤±è´¥: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88747d2f",
   "metadata": {},
   "source": [
    "# <a id='toc1_2_1_'></a>[ä¸åŒç±»å‹æ•°æ®çš„ä¸åŒå¤„ç†æ–¹å¼è¯´æ˜](#toc0_)\n",
    "\n",
    "\n",
    "è¿™é‡Œé’ˆå¯¹çš„æ˜¯ä½¿ç”¨xgboostæ¨¡å‹è€Œè¨€çš„ã€‚\n",
    "\n",
    "one-hot encodingé€‚åˆç‰¹å¾çš„ç§ç±»æ¯”è¾ƒå°‘æ—¶ï¼Œä¸”å¯¹åº”äºæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚\n",
    "\n",
    "å½“ç‰¹å¾ç±»åˆ«æ•°é‡>=10æ—¶ï¼Œè€ƒè™‘ä½¿ç”¨ Target Encodingã€‚\n",
    "\n",
    "å¯¹äºä¸åŒçš„æ•°é‡çš„åˆ†ç±»ç‰¹å¾çš„å¤„ç†æ–¹å¼é€‰æ‹©ï¼š\n",
    "\n",
    "1. è¿ç»­å€¼ä½¿ç”¨å½’ä¸€åŒ–ã€‚\n",
    "2. low-cardinality ç‰¹å¾é‡‡ç”¨label encodingçš„æ–¹å¼è¿›è¡Œç¼–ç ã€‚\n",
    "   1. åˆ†ç•Œçº¿åœ¨äºç±»åˆ«æ•°é‡ä¸º10ã€‚\n",
    "3.  high-cardinality ç‰¹å¾é‡‡ç”¨ Target Encoding çš„æ–¹å¼è¿›è¡Œç¼–ç ã€‚\n",
    "\n",
    "\n",
    "|ç‰¹å¾åç§°|è‹±æ–‡|ç±»åˆ«æ•°é‡|ç‰¹å¾å¤„ç†æ–¹å¼|\n",
    "|---|---|---|---|\n",
    "|æ€§åˆ«ä»£ç |Sex|2| Lable Encoding |\n",
    "|è¡€å‹ä»£ç | BloodType |6 |Lable Encoding |\n",
    "|æ°‘æ—ä»£ç | NationCode |48 | Target Encoding |\n",
    "|å®—æ•™ä¿¡ä»°ä»£ç |ReligiousCode|8| Lable Encoding |\n",
    "|å­¦å†ä»£ç  |EducationCode|35| Target Encoding |\n",
    "|å©šå§»çŠ¶å†µä»£ç |MaritalStatus|8| Lable Encoding |\n",
    "|å…µå½¹çŠ¶å†µä»£ç |MilitaryStatus|6| Lable Encoding |\n",
    "|èŒä¸šç±»åˆ«ä»£ç | OccupationCode| 462| Target Encoding |\n",
    "|èŒä¸š|Occupation|8746| Target Encoding |\n",
    "|ç±è´¯_å›½å®¶å’Œåœ°åŒºä»£ç |OriginCountryCode|7| Lable Encoding |\n",
    "|ç±è´¯_è¡Œæ”¿åŒºåˆ’ä»£ç |OriginAreaCode|3075| Target Encoding |\n",
    "|å‡ºç”Ÿåœ°_å›½å®¶å’Œåœ°åŒºä»£ç |BirthCountryCode|17| Target Encoding |\n",
    "|å‡ºç”Ÿåœ°_è¡Œæ”¿åŒºåˆ’ä»£ç |BirthAreaCode|3157| Target Encoding |\n",
    "|æœåŠ¡å¤„æ‰€|ServicePlace|195248| Target Encoding |\n",
    "|æ‰€å±çœå¸‚å¿ï¼ˆåŒºï¼‰|Province|13| Target Encoding |\n",
    "|äººå‘˜ç±»å‹|PersonnelType|1| / ä¸å¤„ç†|\n",
    "|è¡Œä¸šç±»åˆ«|IndustryCategory|202| Target Encoding |\n",
    "|åŒºå¿|District|13| Target Encoding |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb714c94",
   "metadata": {},
   "source": [
    "# KFlodå¤„ç†å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4eac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "numeric_features = ['Height', 'Age',\n",
    "                    'ain_1', 'ain_2', 'ain_3', 'ain_4', 'ain_5', 'ain_6', \n",
    "                    'fcp_1', 'fcp_2', 'fcp_3', 'fcp_4', 'fcp_5', 'fcp_6', \n",
    "                    'fcn_1', 'fcn_2', 'fcn_3', 'fcn_4', 'fcn_5', 'fcn_6', \n",
    "                    'rac', 'rhp', 'rsp', 'sapn', \n",
    "                    'spn_1', 'spn_2', \n",
    "                    'ncdrppm_1', 'ncdrppm_2', 'ncdrppm_3', 'ncdrppm_4', 'ncdrppm_5', 'ncdrppm_6', \n",
    "                    'nsiswsrpm_1', 'nsiswsrpm_2', 'nsiswsrpm_3', 'nsiswsrpm_4', 'nsiswsrpm_5', 'nsiswsrpm_6', \n",
    "                    'nswsspm_1', 'nswsspm_2', 'nswsspm_3', 'nswsspm_4', 'nswsspm_5', 'nswsspm_6', \n",
    "                    'nsiswsspm_1', 'nsiswsspm_2', 'nsiswsspm_3', 'nsiswsspm_4', 'nsiswsspm_5', 'nsiswsspm_6', \n",
    "                    'nswsrpm_1', 'nswsrpm_2', 'nswsrpm_3', 'nswsrpm_4', 'nswsrpm_5', 'nswsrpm_6']\n",
    "low_card_features = ['Sex', 'BloodType', 'ReligiousCode', 'MaritalStatus', 'MilitaryStatus', 'OriginCountryCode']\n",
    "categorical_features = ['NationCode', 'EducationCode', 'OccupationCode', 'Occupation', 'OriginAreaCode', \n",
    "                        'BirthCountryCode', 'BirthAreaCode', 'ServicePlace', 'Province', 'IndustryCategory', \n",
    "                        'PersonnelType', 'District']\n",
    "\n",
    "# åŠ è½½æ¨¡å‹ä¿¡æ¯ã€‚\n",
    "class KFoldTargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, n_splits=5, smoothing=10, random_state=42):\n",
    "        self.cols = cols\n",
    "        self.n_splits = n_splits\n",
    "        self.smoothing = smoothing\n",
    "        self.random_state = random_state\n",
    "        self.maps_ = {}\n",
    "        self.global_mean = None\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.maps_ = {}\n",
    "        self.global_mean = np.mean(Y)\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        x = X.copy()\n",
    "        y = Y.copy()\n",
    "        # df['__target__'] = Y\n",
    "        \n",
    "        for col in self.cols:\n",
    "            out_of_fold_map = {}\n",
    "            for train_idx, val_idx in kf.split(x):\n",
    "                x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n",
    "                means = y_train.groupby(x_train[col]).mean()\n",
    "                out_of_fold_map.update(means.to_dict())\n",
    "            self.maps_[col] = out_of_fold_map\n",
    "        return self\n",
    "    \n",
    "    def get_feature_names_out(self, input_feature=None):\n",
    "        return [col + '_te' for col in self.cols]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        \n",
    "        for col in self.cols:\n",
    "            X_[col + '_te'] = X_[col].map(self.maps_[col]).fillna(self.global_mean)\n",
    "        return X_[[col + '_te' for col in self.cols]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "PersonInfo_dw_features[numeric_features] = PersonInfo_dw_features[numeric_features].astype(int)\n",
    "PersonInfo_dw_features[low_card_features] = PersonInfo_dw_features[low_card_features].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244a042",
   "metadata": {},
   "source": [
    "# æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = PersonInfo_dw_features[['Sex', 'Height', 'BloodType', 'NationCode',\n",
    "       'ReligiousCode', 'EducationCode', 'MaritalStatus', 'MilitaryStatus',\n",
    "       'OccupationCode', 'Occupation', 'OriginCountryCode', 'OriginAreaCode',\n",
    "       'BirthCountryCode', 'BirthAreaCode', 'ServicePlace', 'Province',\n",
    "       'IndustryCategory', 'PersonnelType', 'District', 'Age', 'Label',\n",
    "       'ain_1', 'ain_2', 'ain_3', 'ain_4', 'ain_5', 'ain_6', 'fcp_1', 'fcp_2',\n",
    "       'fcp_3', 'fcp_4', 'fcp_5', 'fcp_6', 'fcn_1', 'fcn_2', 'fcn_3', 'fcn_4',\n",
    "       'fcn_5', 'fcn_6', 'rac', 'rhp', 'rsp', 'sapn', 'spn_1', 'spn_2',\n",
    "       'ncdrppm_1', 'ncdrppm_2', 'ncdrppm_3', 'ncdrppm_4', 'ncdrppm_5',\n",
    "       'ncdrppm_6', 'nsiswsrpm_1', 'nsiswsrpm_2', 'nsiswsrpm_3', 'nsiswsrpm_4',\n",
    "       'nsiswsrpm_5', 'nsiswsrpm_6', 'nswsspm_1', 'nswsspm_2', 'nswsspm_3',\n",
    "       'nswsspm_4', 'nswsspm_5', 'nswsspm_6', 'nsiswsspm_1', 'nsiswsspm_2',\n",
    "       'nsiswsspm_3', 'nsiswsspm_4', 'nsiswsspm_5', 'nsiswsspm_6', 'nswsrpm_1',\n",
    "       'nswsrpm_2', 'nswsrpm_3', 'nswsrpm_4', 'nswsrpm_5', 'nswsrpm_6']]\n",
    "labels = PersonInfo_dw_features['Label']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), low_card_features),\n",
    "#     # ('target_encoder', ce.TargetEncoder(cols=categorical_features), categorical_features),\n",
    "    ('target_encoder', KFoldTargetEncoder(cols=categorical_features), categorical_features),\n",
    "    # ('passthrough', '')\n",
    "])\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "               ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, labels, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'f1': make_scorer(f1_score),\n",
    "           'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "# ç¬¬ä¸€é˜¶æ®µçš„ç²—æœç´¢ã€‚\n",
    "parameters_dist = {\n",
    "    'classifier__n_estimators': [50, 100, 150, 200, 300], # å¤šå°‘é¢—æ ‘ã€‚\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3], # å­¦ä¹ ç‡ã€‚\n",
    "    'classifier__max_depth': [3, 4, 5, 6, 7], # æ ‘çš„æœ€å¤§æ·±åº¦ã€‚\n",
    "    'classifier__colsample_bytree': [0.4, 0.6, 0.8, 1], # é€‰æ‹©å¤šå°‘åˆ—æ„å»ºä¸€ä¸ªæ ‘ã€‚\n",
    "    'classifier__min_child_weight': [1, 2, 3, 4] # å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°é‡ã€‚\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pl, \n",
    "    param_distributions=parameters_dist,\n",
    "    n_iter=5,\n",
    "    scoring=scoring,\n",
    "    refit='f1', # ä»¥ f1 ä¸ºç›®æ ‡è¿›è¡Œä¼˜åŒ–ã€‚\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print('[stage 1] best parameters :', random_search.best_params_)\n",
    "\n",
    "\n",
    "# ç¬¬äºŒé˜¶æ®µçš„ç»†è°ƒã€‚\n",
    "best_params = random_search.best_params_\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [best_params['classifier__n_estimators'] -50,\n",
    "                                 best_params['classifier__n_estimators'],\n",
    "                                 best_params['classifier__n_estimators'] + 50],\n",
    "    'classifier__max_depth': [max(1, best_params['classifier__max_depth'] - 1),\n",
    "                              best_params['classifier__max_depth'],\n",
    "                              best_params['classifier__max_depth'] + 1],\n",
    "    'classifier__learning_rate': [round(best_params['classifier__learning_rate'], 3)]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    random_search.best_estimator_, \n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1', # ä»¥ f1 ä¸ºç›®æ ‡è¿›è¡Œä¼˜åŒ–ã€‚\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('[stage 2] best parameters : {}'.format(grid_search.best_params_))\n",
    "print('[stage 2] best score : {}'.format(grid_search.best_score_))\n",
    "\n",
    "# é¢„æµ‹\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "print('accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "scores = cross_val_score(best_model, samples, labels, cv=5)\n",
    "print('mean accuracy :{}'.format(scores.mean()))\n",
    "\n",
    "# è€—æ—¶15.1s ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b34107",
   "metadata": {},
   "source": [
    "# è¯„ä¼°ç‰¹å¾\n",
    "\n",
    "éœ€è¦ä¸€ä¸€åˆ—ä¸¾å…¥ç›¸å…³ç³»æ•°ç­‰å‡½æ•°çš„æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45afaa",
   "metadata": {},
   "source": [
    "# æ··æ·†çŸ©é˜µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./pictures/ConfusionMatrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99113c8",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96115642",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (area = {roc_auc:.2f})', color='darkorange')\n",
    "plt.title('ROC Curve')\n",
    "# plt.text(0.5, 0.3, 'ROC curve (area =%0.2f)'%roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./pictures/ROCCurve.png')\n",
    "plt.show()\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ca873",
   "metadata": {},
   "source": [
    "# ç‰¹å¾é‡è¦æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ac1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = best_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "importances = best_model.named_steps['classifier'].feature_importances_\n",
    "# importances\n",
    "# ä¸ç‰¹å¾åç§°ç»‘å®šã€‚\n",
    "for name, score in zip(feature_names, importances):\n",
    "    print(f\"{name:20s} : {score:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c2bc42",
   "metadata": {},
   "source": [
    "# ä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f63e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, './data/model_pipeline.pkl')\n",
    "joblib.dump(best_model.named_steps['preprocessor'].get_feature_names_out(), './data/feature_names.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
