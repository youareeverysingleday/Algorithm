{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e591631",
   "metadata": {},
   "source": [
    "# 经验\n",
    "\n",
    "1. 对于不同的数量的分类特征的处理方式选择：\n",
    "   1. 连续值使用归一化。\n",
    "   2. low-cardinality 特征采用label encoding的方式进行编码。\n",
    "      1. 分界线在于类别数量为10。\n",
    "   3.  high-cardinality 特征采用 Target Encoding 的方式进行编码。\n",
    "2. kmeans不建议使用网格搜索来获取最优值，容易出现报错。直接手动搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743835d",
   "metadata": {},
   "source": [
    "# 题目\n",
    "\n",
    "## 数据说明\n",
    "\n",
    "Bob 的初创手机公司需要科学定价策略以对抗苹果、三星等巨头。他收集了 2000+ 款手机的硬件规格数据，要求你构建价格分档预测模型。根据行业惯例，价格分为4档：\n",
    "0=低端(＜$200) | 1=中端($200-$400) | 2=高端($400-$600) | 3=旗舰(＞$600)\n",
    "\n",
    "字段说明（21个字段）\n",
    "|字段名\t|类型\t|说明\t|示例值|\n",
    "|---|---|---|---|\n",
    "|id\t|数值\t|手机唯一ID（建模时忽略）\t|3|\n",
    "|battery_power\t|数值\t|电池容量(mAh)\t|1024|\n",
    "|blue\t|分类\t|蓝牙支持：0=无,1=有\t|1|\n",
    "|clock_speed\t|数值\t|处理器主频(GHz)\t|2.5|\n",
    "|dual_sim\t|分类\t|双卡支持：0=无,1=有\t|0|\n",
    "|fc\t|数值\t|前置摄像头像素(MP)\t|8|\n",
    "|four_g\t|分类\t|4G支持：0=无,1=有\t|1|\n",
    "|int_memory\t|数值\t|内部存储(GB)|\t64|\n",
    "|m_dep\t|数值\t|手机厚度(cm)\t|0.8|\n",
    "|mobile_wt\t|数值\t|手机重量(g)\t|188|\n",
    "|n_cores|\t数值\t|处理器核心数\t|8|\n",
    "|pc\t|数值\t|主摄像头像素(MP)\t|13|\n",
    "|px_height\t|数值\t|屏幕垂直分辨率(像素)\t|905|\n",
    "|px_width|\t数值\t|屏幕水平分辨率(像素)\t|1988|\n",
    "|ram\t|数值\t|运行内存(MB)\t|2632|\n",
    "|sc_h\t|数值\t|屏幕高度(cm)\t|15|\n",
    "|sc_w\t|数值\t|屏幕宽度(cm)\t|7|\n",
    "|talk_time\t|数值\t|通话时长(小时)\t|12|\n",
    "|three_g\t|分类\t|3G支持：0=无,1=有\t|1|\n",
    "|touch_screen\t|分类\t|触摸屏：0=无,1=有\t|1|\n",
    "|wifi\t|分类\t|WiFi支持：0=无,1=有\t|1|\n",
    "|price_range\t|分类\t|目标变量：价格分档\t|2|\n",
    "\n",
    "注意：测试集不含 price_range 字段\n",
    "\n",
    "## 任务说明\n",
    "完成以下流程：\n",
    "\n",
    "1. 数据处理\n",
    "   - 处理缺失值：px_height 和 px_width 有少量缺失，用均值填充。\n",
    "   - 处理异常值：px_height 和 px_width 为0的记录视为异常值，直接删除。\n",
    "   - 标准化数值特征：标准化所有数值特征（使用StandardScaler），包括但不限于battery_power, ram, px_height, px_width等。\n",
    "   - 所有预处理操作（缺失值填充、异常值处理、标准化）\n",
    "   - 必须同时应用于训练集和测试集\n",
    "2. 模型构建\n",
    "   - 选择合适的分类模型\n",
    "   - 在训练集上使用5折交叉验证计算F1-score（宏平均）作为自评估指标\n",
    "3. 预测与保存\n",
    "   - 预测测试集 test.csv 的价格分档\n",
    "   - 生成提交文件 predictions.csv 格式：\n",
    "        ```csv\n",
    "        id,price_range\n",
    "        1000,1\n",
    "        1001,3\n",
    "        ...\n",
    "        ```\n",
    "   \n",
    "## 提交物\n",
    "\n",
    "1. 模型文件\n",
    "   - model.pkl\n",
    "   - 使用joblib保存：\n",
    "   - joblib.dump(model, 'model.pkl')\n",
    "2. 预测结果文件\n",
    "   - predictions.csv（含两列：id 和预测的 price_range）\n",
    "   - 以上两个文件一同打包为一个压缩包文件后提交，命名为：submit.zip\n",
    "3. 在答题区题写自评估F1-score（宏平均）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa3cd8",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0ebfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, roc_curve, make_scorer, confusion_matrix, classification_report, RocCurveDisplay, auc\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# from ModelInformation import KFoldTargetEncoder, numeric_features, low_card_features, categorical_features\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067e8f4",
   "metadata": {},
   "source": [
    "# 确定模型类别\n",
    "\n",
    "1. 是分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff81e5c",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca8c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/2/train.csv')\n",
    "test = pd.read_csv('./Data/2/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca26d71",
   "metadata": {},
   "source": [
    "# 查看数据基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827bd56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
       "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
       "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
       "       'touch_screen', 'wifi', 'price_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f036f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of blue sort 2\n",
      "number of dual_sim sort 2\n",
      "number of four_g sort 2\n",
      "number of three_g sort 2\n",
      "number of touch_screen sort 2\n",
      "number of wifi sort 2\n"
     ]
    }
   ],
   "source": [
    "def StatisticFeature(df):\n",
    "    # print(PeopleInfo_selected['Sex'].value_counts()) 这是统计每个类别的数量。\n",
    "    print('number of blue sort {}'.format(df['blue'].nunique()))\n",
    "    print('number of dual_sim sort {}'.format(df['dual_sim'].nunique()))\n",
    "    print('number of four_g sort {}'.format(df['four_g'].nunique()))\n",
    "    print('number of three_g sort {}'.format(df['three_g'].nunique()))\n",
    "    print('number of touch_screen sort {}'.format(df['touch_screen'].nunique()))\n",
    "    print('number of wifi sort {}'.format(df['wifi'].nunique()))\n",
    "StatisticFeature(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee12b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']\n",
    "low_cardinality_features = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']\n",
    "\n",
    "# print(len(numeric_features))\n",
    "# print(len(numeric_features)+ len(low_cardinality_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87df9d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 21) (1000, 21)\n",
      "{'price_range', 'id'}\n"
     ]
    }
   ],
   "source": [
    "# 数据形状。\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "trainset = set(train.columns)\n",
    "testset = set(test.columns)\n",
    "# 数据列的不同。\n",
    "print(testset.symmetric_difference(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc4ee27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
       "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
       "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
       "       'touch_screen', 'wifi', 'price_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54287cba",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "\n",
    "## 数据初级处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b105ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9976\\4219749616.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna(train[col].mean(), inplace=True)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9976\\4219749616.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[col].fillna(test[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for col in ['px_height', 'px_width']:\n",
    "    train[col] = train[col].replace(0, np.nan)  # 将0视为缺失\n",
    "    train[col].fillna(train[col].mean(), inplace=True)\n",
    "\n",
    "    test[col] = test[col].replace(0, np.nan)  # 将0视为缺失\n",
    "    test[col].fillna(test[col].mean(), inplace=True)\n",
    "\n",
    "# 删除无意义的列。\n",
    "test.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# 获取标签列和特征列。\n",
    "labels = train['price_range'].astype(int)\n",
    "samples = train.drop(columns=['price_range'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0bbd6",
   "metadata": {},
   "source": [
    "## 数据高级处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "815d0910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1213: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一阶段最优参数： {'classifier__penalty': 'l1', 'classifier__l1_ratio': np.float64(0.3333333333333333), 'classifier__C': np.float64(11.288378916846883)}\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第二阶段最优参数： {'classifier__C': np.float64(5.644189458423441), 'classifier__penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), low_cardinality_features),\n",
    "#     # ('target_encoder', ce.TargetEncoder(cols=categorical_features), categorical_features),\n",
    "    # ('target_encoder', KFoldTargetEncoder(cols=categorical_features), categorical_features),\n",
    "    # ('passthrough', '')\n",
    "])\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='saga'))\n",
    "               ])\n",
    "\n",
    "X_train, X_Validation, y_train, y_Validation = train_test_split(samples, labels, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 注意本题是以f1为目标。\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'f1': make_scorer(f1_score),\n",
    "           'roc_auc': make_scorer(roc_auc_score)}\n",
    "# scoring = {'f1': make_scorer(f1_score)}\n",
    "\n",
    "\n",
    "# 第一阶段的粗搜索。\n",
    "parameters_dist = {\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'classifier__C': np.logspace(-4, 4, 20),\n",
    "    'classifier__l1_ratio': np.linspace(0, 1, 10), \n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pl,\n",
    "    param_distributions=parameters_dist,\n",
    "    n_iter=20,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',  # 使用f1作为最终模型的评估标准\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"第一阶段最优参数：\", random_search.best_params_)\n",
    "\n",
    "# 第二阶段：网格搜索（精调）\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "penalty = best_params['classifier__penalty']\n",
    "C = best_params['classifier__C']\n",
    "\n",
    "# 构造精调网格\n",
    "if penalty == 'elasticnet':\n",
    "    param_grid = {\n",
    "        'classifier__penalty': [penalty],\n",
    "        'classifier__C': [C * 0.5, C, C * 2],\n",
    "        'classifier__l1_ratio': np.linspace(0.2, 0.8, 5),\n",
    "    }\n",
    "else:\n",
    "    param_grid = {\n",
    "        'classifier__penalty': [penalty],\n",
    "        'classifier__C': [C * 0.5, C, C * 2],\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pl,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"第二阶段最优参数：\", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff016dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV Macro F1-score: 0.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scores = cross_val_score(best_model, train, labels, cv=cv, scoring='f1_macro')\n",
    "\n",
    "print(f\"5-fold CV Macro F1-score: {f1_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "831c6586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试集评估:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75       500\n",
      "           1       0.53      0.36      0.43       500\n",
      "           2       0.00      0.00      0.00       500\n",
      "           3       0.59      0.99      0.74       500\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.43      0.58      0.48      2000\n",
      "weighted avg       0.43      0.58      0.48      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# 5. 测试集评估\n",
    "y_pred = best_model.predict(train)\n",
    "# y_pred\n",
    "print(\"\\n测试集评估:\")\n",
    "print(classification_report(y_true=labels, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f082056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5845\n",
      "mean accuracy :0.531\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = best_model.predict(train)\n",
    "y_proba = best_model.predict_proba(train)[:, 1]\n",
    "print('accuracy: {}'.format(accuracy_score(labels, y_pred)))\n",
    "\n",
    "scores = cross_val_score(best_model, samples, labels, cv=5)\n",
    "print('mean accuracy :{}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d58cd7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data/model.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, './Data/model.pkl')\n",
    "# joblib.dump(best_model.named_steps['preprocessor'].get_feature_names_out(), './Data/feature_names.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2525955",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(best_model.predict(test))\n",
    "y_pred.to_csv('./Data/predictions.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499f203",
   "metadata": {},
   "source": [
    "# 多个模型的模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 1. 加载示例数据\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)\n",
    "\n",
    "# 2. 定义模型字典\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(solver='saga', max_iter=10000),\n",
    "    \"SVC\": SVC(probability=True),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# 3. 定义每个模型的搜索空间\n",
    "param_distributions = {\n",
    "    \"LogisticRegression\": {\n",
    "        'clf__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'clf__C': np.logspace(-4, 4, 10),\n",
    "        'clf__l1_ratio': np.linspace(0, 1, 5)  # 仅在 elasticnet 中有效\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'clf__C': np.logspace(-3, 2, 6),\n",
    "        'clf__gamma': ['scale', 'auto'],\n",
    "        'clf__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [None, 5, 10, 20],\n",
    "        'clf__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        'clf__max_depth': [None, 5, 10, 20],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. 自动化调参和评估\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 正在搜索模型: {name}\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_distributions[name],\n",
    "        n_iter=20,\n",
    "        scoring='accuracy',\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        verbose=0,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    best_models[name] = search.best_estimator_\n",
    "    \n",
    "    print(f\"✅ 最佳参数: {search.best_params_}\")\n",
    "    print(f\"📊 交叉验证准确率: {search.best_score_:.4f}\")\n",
    "\n",
    "    # 评估测试集\n",
    "    y_pred = search.predict(X_test)\n",
    "    print(\"📋 测试集结果:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 可选：比较不同模型最终在测试集的准确率等\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811683cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 正在搜索模型: LogisticRegression\n",
      "✅ 模型 LogisticRegression 的测试准确率: 0.9649\n",
      "🔍 正在搜索模型: RandomForest\n",
      "✅ 模型 RandomForest 的测试准确率: 0.9561\n",
      "🔍 正在搜索模型: SVC\n",
      "✅ 模型 SVC 的测试准确率: 0.9825\n",
      "\n",
      "🏆 最优模型为: SVC，准确率: 0.9825\n",
      "💾 模型已保存为: SVC_best_model.pkl\n",
      "\n",
      "📊 特征重要性：\n",
      "❌ 该模型不支持特征重要性输出。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. 加载数据\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. 定义模型及调参空间\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(solver='saga', max_iter=10000),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"SVC\": SVC(probability=True)\n",
    "}\n",
    "\n",
    "param_distributions = {\n",
    "    \"LogisticRegression\": {\n",
    "        'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'clf__C': np.logspace(-4, 4, 10),\n",
    "        'clf__l1_ratio': np.linspace(0, 1, 5)\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [3, 5, 10, None],\n",
    "        'clf__max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'clf__C': np.logspace(-2, 2, 5),\n",
    "        'clf__gamma': ['scale', 'auto'],\n",
    "        'clf__kernel': ['linear', 'rbf']\n",
    "    }\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"LogisticRegression\": {\n",
    "        'clf__penalty': ['l1', 'elasticnet'],\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__l1_ratio': [0.5, 0.7]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__max_depth': [5, 10],\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'clf__C': [1, 10],\n",
    "        'clf__kernel': ['rbf'],\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. 搜索并保存最优模型\n",
    "best_score = 0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "best_pipeline = None\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"🔍 正在搜索模型: {name}\")\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    # 1. 随机搜索\n",
    "    rand_search = RandomizedSearchCV(pipe, param_distributions[name], n_iter=10,\n",
    "                                     scoring='accuracy', cv=cv, random_state=42, n_jobs=-1)\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. 网格搜索（以随机搜索结果为基础）\n",
    "    best_params = rand_search.best_params_\n",
    "    grid_params = param_grids.get(name, {})\n",
    "    grid_search = GridSearchCV(pipe, grid_params, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    acc = accuracy_score(y_test, grid_search.predict(X_test))\n",
    "    print(f\"✅ 模型 {name} 的测试准确率: {acc:.4f}\")\n",
    "    \n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model_name = name\n",
    "        best_pipeline = grid_search\n",
    "\n",
    "# 4. 保存最优模型\n",
    "print(f\"\\n🏆 最优模型为: {best_model_name}，准确率: {best_score:.4f}\")\n",
    "joblib.dump(best_model, f\"{best_model_name}_best_model.pkl\")\n",
    "print(f\"💾 模型已保存为: {best_model_name}_best_model.pkl\")\n",
    "\n",
    "# 5. 打印特征重要性\n",
    "print(\"\\n📊 特征重要性：\")\n",
    "feature_names = X.columns\n",
    "try:\n",
    "    if hasattr(best_model.named_steps['clf'], 'coef_'):\n",
    "        coefs = best_model.named_steps['clf'].coef_\n",
    "        if coefs.ndim == 2:\n",
    "            coefs = coefs[0]\n",
    "        for name, coef in sorted(zip(feature_names, coefs), key=lambda x: abs(x[1]), reverse=True):\n",
    "            print(f\"{name}: {coef:.4f}\")\n",
    "    elif hasattr(best_model.named_steps['clf'], 'feature_importances_'):\n",
    "        importances = best_model.named_steps['clf'].feature_importances_\n",
    "        for name, importance in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"{name}: {importance:.4f}\")\n",
    "    else:\n",
    "        print(\"❌ 该模型不支持特征重要性输出。\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 特征重要性提取失败: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88747d2f",
   "metadata": {},
   "source": [
    "# <a id='toc1_2_1_'></a>[不同类型数据的不同处理方式说明](#toc0_)\n",
    "\n",
    "\n",
    "这里针对的是使用xgboost模型而言的。\n",
    "\n",
    "one-hot encoding适合特征的种类比较少时，且对应于深度学习模型。\n",
    "\n",
    "当特征类别数量>=10时，考虑使用 Target Encoding。\n",
    "\n",
    "对于不同的数量的分类特征的处理方式选择：\n",
    "\n",
    "1. 连续值使用归一化。\n",
    "2. low-cardinality 特征采用label encoding的方式进行编码。\n",
    "   1. 分界线在于类别数量为10。\n",
    "3.  high-cardinality 特征采用 Target Encoding 的方式进行编码。\n",
    "\n",
    "\n",
    "|特征名称|英文|类别数量|特征处理方式|\n",
    "|---|---|---|---|\n",
    "|性别代码|Sex|2| Lable Encoding |\n",
    "|血型代码| BloodType |6 |Lable Encoding |\n",
    "|民族代码| NationCode |48 | Target Encoding |\n",
    "|宗教信仰代码|ReligiousCode|8| Lable Encoding |\n",
    "|学历代码 |EducationCode|35| Target Encoding |\n",
    "|婚姻状况代码|MaritalStatus|8| Lable Encoding |\n",
    "|兵役状况代码|MilitaryStatus|6| Lable Encoding |\n",
    "|职业类别代码| OccupationCode| 462| Target Encoding |\n",
    "|职业|Occupation|8746| Target Encoding |\n",
    "|籍贯_国家和地区代码|OriginCountryCode|7| Lable Encoding |\n",
    "|籍贯_行政区划代码|OriginAreaCode|3075| Target Encoding |\n",
    "|出生地_国家和地区代码|BirthCountryCode|17| Target Encoding |\n",
    "|出生地_行政区划代码|BirthAreaCode|3157| Target Encoding |\n",
    "|服务处所|ServicePlace|195248| Target Encoding |\n",
    "|所属省市县（区）|Province|13| Target Encoding |\n",
    "|人员类型|PersonnelType|1| / 不处理|\n",
    "|行业类别|IndustryCategory|202| Target Encoding |\n",
    "|区县|District|13| Target Encoding |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb714c94",
   "metadata": {},
   "source": [
    "# KFlod处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4eac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "numeric_features = ['Height', 'Age',\n",
    "                    'ain_1', 'ain_2', 'ain_3', 'ain_4', 'ain_5', 'ain_6', \n",
    "                    'fcp_1', 'fcp_2', 'fcp_3', 'fcp_4', 'fcp_5', 'fcp_6', \n",
    "                    'fcn_1', 'fcn_2', 'fcn_3', 'fcn_4', 'fcn_5', 'fcn_6', \n",
    "                    'rac', 'rhp', 'rsp', 'sapn', \n",
    "                    'spn_1', 'spn_2', \n",
    "                    'ncdrppm_1', 'ncdrppm_2', 'ncdrppm_3', 'ncdrppm_4', 'ncdrppm_5', 'ncdrppm_6', \n",
    "                    'nsiswsrpm_1', 'nsiswsrpm_2', 'nsiswsrpm_3', 'nsiswsrpm_4', 'nsiswsrpm_5', 'nsiswsrpm_6', \n",
    "                    'nswsspm_1', 'nswsspm_2', 'nswsspm_3', 'nswsspm_4', 'nswsspm_5', 'nswsspm_6', \n",
    "                    'nsiswsspm_1', 'nsiswsspm_2', 'nsiswsspm_3', 'nsiswsspm_4', 'nsiswsspm_5', 'nsiswsspm_6', \n",
    "                    'nswsrpm_1', 'nswsrpm_2', 'nswsrpm_3', 'nswsrpm_4', 'nswsrpm_5', 'nswsrpm_6']\n",
    "low_card_features = ['Sex', 'BloodType', 'ReligiousCode', 'MaritalStatus', 'MilitaryStatus', 'OriginCountryCode']\n",
    "categorical_features = ['NationCode', 'EducationCode', 'OccupationCode', 'Occupation', 'OriginAreaCode', \n",
    "                        'BirthCountryCode', 'BirthAreaCode', 'ServicePlace', 'Province', 'IndustryCategory', \n",
    "                        'PersonnelType', 'District']\n",
    "\n",
    "# 加载模型信息。\n",
    "class KFoldTargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, n_splits=5, smoothing=10, random_state=42):\n",
    "        self.cols = cols\n",
    "        self.n_splits = n_splits\n",
    "        self.smoothing = smoothing\n",
    "        self.random_state = random_state\n",
    "        self.maps_ = {}\n",
    "        self.global_mean = None\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.maps_ = {}\n",
    "        self.global_mean = np.mean(Y)\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        x = X.copy()\n",
    "        y = Y.copy()\n",
    "        # df['__target__'] = Y\n",
    "        \n",
    "        for col in self.cols:\n",
    "            out_of_fold_map = {}\n",
    "            for train_idx, val_idx in kf.split(x):\n",
    "                x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n",
    "                means = y_train.groupby(x_train[col]).mean()\n",
    "                out_of_fold_map.update(means.to_dict())\n",
    "            self.maps_[col] = out_of_fold_map\n",
    "        return self\n",
    "    \n",
    "    def get_feature_names_out(self, input_feature=None):\n",
    "        return [col + '_te' for col in self.cols]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        \n",
    "        for col in self.cols:\n",
    "            X_[col + '_te'] = X_[col].map(self.maps_[col]).fillna(self.global_mean)\n",
    "        return X_[[col + '_te' for col in self.cols]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "PersonInfo_dw_features[numeric_features] = PersonInfo_dw_features[numeric_features].astype(int)\n",
    "PersonInfo_dw_features[low_card_features] = PersonInfo_dw_features[low_card_features].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244a042",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = PersonInfo_dw_features[['Sex', 'Height', 'BloodType', 'NationCode',\n",
    "       'ReligiousCode', 'EducationCode', 'MaritalStatus', 'MilitaryStatus',\n",
    "       'OccupationCode', 'Occupation', 'OriginCountryCode', 'OriginAreaCode',\n",
    "       'BirthCountryCode', 'BirthAreaCode', 'ServicePlace', 'Province',\n",
    "       'IndustryCategory', 'PersonnelType', 'District', 'Age', 'Label',\n",
    "       'ain_1', 'ain_2', 'ain_3', 'ain_4', 'ain_5', 'ain_6', 'fcp_1', 'fcp_2',\n",
    "       'fcp_3', 'fcp_4', 'fcp_5', 'fcp_6', 'fcn_1', 'fcn_2', 'fcn_3', 'fcn_4',\n",
    "       'fcn_5', 'fcn_6', 'rac', 'rhp', 'rsp', 'sapn', 'spn_1', 'spn_2',\n",
    "       'ncdrppm_1', 'ncdrppm_2', 'ncdrppm_3', 'ncdrppm_4', 'ncdrppm_5',\n",
    "       'ncdrppm_6', 'nsiswsrpm_1', 'nsiswsrpm_2', 'nsiswsrpm_3', 'nsiswsrpm_4',\n",
    "       'nsiswsrpm_5', 'nsiswsrpm_6', 'nswsspm_1', 'nswsspm_2', 'nswsspm_3',\n",
    "       'nswsspm_4', 'nswsspm_5', 'nswsspm_6', 'nsiswsspm_1', 'nsiswsspm_2',\n",
    "       'nsiswsspm_3', 'nsiswsspm_4', 'nsiswsspm_5', 'nsiswsspm_6', 'nswsrpm_1',\n",
    "       'nswsrpm_2', 'nswsrpm_3', 'nswsrpm_4', 'nswsrpm_5', 'nswsrpm_6']]\n",
    "labels = PersonInfo_dw_features['Label']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), low_card_features),\n",
    "#     # ('target_encoder', ce.TargetEncoder(cols=categorical_features), categorical_features),\n",
    "    ('target_encoder', KFoldTargetEncoder(cols=categorical_features), categorical_features),\n",
    "    # ('passthrough', '')\n",
    "])\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "               ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, labels, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'f1': make_scorer(f1_score),\n",
    "           'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "# 第一阶段的粗搜索。\n",
    "parameters_dist = {\n",
    "    'classifier__n_estimators': [50, 100, 150, 200, 300], # 多少颗树。\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3], # 学习率。\n",
    "    'classifier__max_depth': [3, 4, 5, 6, 7], # 树的最大深度。\n",
    "    'classifier__colsample_bytree': [0.4, 0.6, 0.8, 1], # 选择多少列构建一个树。\n",
    "    'classifier__min_child_weight': [1, 2, 3, 4] # 叶子节点最小样本数量。\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pl, \n",
    "    param_distributions=parameters_dist,\n",
    "    n_iter=5,\n",
    "    scoring=scoring,\n",
    "    refit='f1', # 以 f1 为目标进行优化。\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print('[stage 1] best parameters :', random_search.best_params_)\n",
    "\n",
    "\n",
    "# 第二阶段的细调。\n",
    "best_params = random_search.best_params_\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [best_params['classifier__n_estimators'] -50,\n",
    "                                 best_params['classifier__n_estimators'],\n",
    "                                 best_params['classifier__n_estimators'] + 50],\n",
    "    'classifier__max_depth': [max(1, best_params['classifier__max_depth'] - 1),\n",
    "                              best_params['classifier__max_depth'],\n",
    "                              best_params['classifier__max_depth'] + 1],\n",
    "    'classifier__learning_rate': [round(best_params['classifier__learning_rate'], 3)]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    random_search.best_estimator_, \n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1', # 以 f1 为目标进行优化。\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('[stage 2] best parameters : {}'.format(grid_search.best_params_))\n",
    "print('[stage 2] best score : {}'.format(grid_search.best_score_))\n",
    "\n",
    "# 预测\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "print('accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "scores = cross_val_score(best_model, samples, labels, cv=5)\n",
    "print('mean accuracy :{}'.format(scores.mean()))\n",
    "\n",
    "# 耗时15.1s 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b34107",
   "metadata": {},
   "source": [
    "# 评估特征\n",
    "\n",
    "需要一一列举入相关系数等函数的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45afaa",
   "metadata": {},
   "source": [
    "# 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./pictures/ConfusionMatrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99113c8",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96115642",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (area = {roc_auc:.2f})', color='darkorange')\n",
    "plt.title('ROC Curve')\n",
    "# plt.text(0.5, 0.3, 'ROC curve (area =%0.2f)'%roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./pictures/ROCCurve.png')\n",
    "plt.show()\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ca873",
   "metadata": {},
   "source": [
    "# 特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ac1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = best_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "importances = best_model.named_steps['classifier'].feature_importances_\n",
    "# importances\n",
    "# 与特征名称绑定。\n",
    "for name, score in zip(feature_names, importances):\n",
    "    print(f\"{name:20s} : {score:4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c2bc42",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f63e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, './data/model_pipeline.pkl')\n",
    "joblib.dump(best_model.named_steps['preprocessor'].get_feature_names_out(), './data/feature_names.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
